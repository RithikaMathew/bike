{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f57fe801",
   "metadata": {},
   "source": [
    "# Bike Data Processing - Complete Pipeline\n",
    "This notebook:\n",
    "1. Loads the Excel file with bike crash data\n",
    "2. Filters to rows with Bike Type values\n",
    "3. Extracts ZIP files containing crash report PDFs\n",
    "4. Matches HSMV Report Numbers with PDF files\n",
    "5. Extracts narrative text from matching PDFs\n",
    "6. Generates statistics and saves results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df526bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "!pip install PyPDF2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40874d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file: nolabeluse.xlsx\n",
      "Reports folder: reports\n",
      "Output file: bike_data_with_narratives.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Configuration - adjust paths if needed\n",
    "excel_file = \"nolabeluse.xlsx\"\n",
    "reports_folder = \"/content/drive/MyDrive/reports\"\n",
    "output_file = \"bike_data_with_narratives.xlsx\"\n",
    "\n",
    "print(f\"Excel file: {excel_file}\")\n",
    "print(f\"Reports folder: {reports_folder}\")\n",
    "print(f\"Output file: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b0c30",
   "metadata": {},
   "source": [
    "## Step 1: Load and Filter Excel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ced3a746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (9031, 45)\n",
      "\n",
      "Columns in original file:\n",
      "  - HSMV_Report_Number\n",
      "  - Reporting_Agency\n",
      "  - Form_Type\n",
      "  - Year\n",
      "  - Crash_Date\n",
      "  - Crash_Time\n",
      "  - City\n",
      "  - County\n",
      "  - Crash_Street\n",
      "  - Intersecting_Street\n",
      "  - Vehicles\n",
      "  - Non_Motorists\n",
      "  - Fatalities\n",
      "  - Injuries\n",
      "  - Alcohol_Related\n",
      "  - Distraction_Related\n",
      "  - Drug_Related\n",
      "  - Weather_Condition\n",
      "  - Light_Condition\n",
      "  - Crash_Severity\n",
      "  - Type_of_Intersection\n",
      "  - Road_Sys_Identifier\n",
      "  - Type_of_Shoulder\n",
      "  - Road_Surf_Cond\n",
      "  - Bicyclists\n",
      "  - Possible_Injuries\n",
      "  - Non_Incapacitating_Injuries\n",
      "  - Incapacitating_Injuries\n",
      "  - Fatalities_30_Days\n",
      "  - Non_Traffic_Fatalities\n",
      "  - S4_Mapping\n",
      "  - S4_Decimal_Degree_Longitude\n",
      "  - S4_Decimal_Degree_Latitude\n",
      "  - S4_Albers_X\n",
      "  - S4_Albers_Y\n",
      "  - S4_Mapping_Date\n",
      "  - Bike_Crash_Group_Number\n",
      "  - Bike_Crash_Group\n",
      "  - Bike_Crash_Type_Number\n",
      "  - Bike_Crash_Type\n",
      "  - Bike_Crash_Location\n",
      "  - Bike_Bicyclist_Direction\n",
      "  - Bike_Bicyclist_Position\n",
      "  - Bike_Typing_Notes\n",
      "  - Bike Type\n"
     ]
    }
   ],
   "source": [
    "# Read the Excel file\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "print(f\"Original data shape: {df.shape}\")\n",
    "print(f\"\\nColumns in original file:\")\n",
    "for col in df.columns:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0b146d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered data shape: (111, 4)\n",
      "Rows kept: 111\n",
      "Rows removed: 8920\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HSMV_Report_Number</th>\n",
       "      <th>Bike Type</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>82089001</td>\n",
       "      <td>Motorized bicycle</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>81994356</td>\n",
       "      <td>Motorized bicycle</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>82877472</td>\n",
       "      <td>E-trike</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>83350430</td>\n",
       "      <td>Pedicab</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>83353372</td>\n",
       "      <td>Motorized bicycle</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HSMV_Report_Number          Bike Type Narrative Match\n",
       "403             82089001  Motorized bicycle              No\n",
       "530             81994356  Motorized bicycle              No\n",
       "745             82877472            E-trike              No\n",
       "927             83350430            Pedicab              No\n",
       "1031            83353372  Motorized bicycle              No"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create filtered dataframe with required columns\n",
    "df_filtered = df[['HSMV_Report_Number', 'Bike Type']].copy()\n",
    "\n",
    "# Add empty Narrative and Match columns\n",
    "df_filtered['Narrative'] = ''\n",
    "df_filtered['Match'] = 'No'\n",
    "\n",
    "# Filter: Keep only rows where 'Bike Type' has a value\n",
    "df_filtered = df_filtered[df_filtered['Bike Type'].notna()]\n",
    "df_filtered = df_filtered[df_filtered['Bike Type'].astype(str).str.strip() != '']\n",
    "\n",
    "print(f\"\\nFiltered data shape: {df_filtered.shape}\")\n",
    "print(f\"Rows kept: {len(df_filtered)}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_filtered)}\")\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e8817e",
   "metadata": {},
   "source": [
    "## Step 2: Extract ZIP Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e02a4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 ZIP files in reports\n",
      "\n",
      "First 3 ZIP files:\n",
      "  - S4_Extract_xiangyan_145031_20250507_221605.zip\n",
      "  - S4_Extract_xiangyan_145032_20250507_221817.zip\n",
      "  - S4_Extract_xiangyan_145033_20250507_222016.zip\n"
     ]
    }
   ],
   "source": [
    "# Get list of ZIP files in reports folder\n",
    "zip_files = [f for f in os.listdir(reports_folder) if f.endswith('.zip')]\n",
    "print(f\"Found {len(zip_files)} ZIP files in {reports_folder}\")\n",
    "\n",
    "# Show first few\n",
    "if zip_files:\n",
    "    print(f\"\\nFirst 3 ZIP files:\")\n",
    "    for zf in zip_files[:3]:\n",
    "        print(f\"  - {zf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ec84500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ZIP files...\n",
      "  Already extracted: S4_Extract_xiangyan_145031_20250507_221605.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145032_20250507_221817.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145033_20250507_222016.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145034_20250507_222144.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145035_20250507_222250.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145036_20250507_222415.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145037_20250507_222521.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145038_20250507_222618.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145039_20250507_224519.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145040_20250507_224607.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145041_20250507_224750.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145042_20250507_224908.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145043_20250507_225718.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145044_20250507_225800.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145045_20250507_225834.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145046_20250507_225916.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145047_20250507_230004.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145048_20250507_230054.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145049_20250507_230324.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145050_20250507_230438.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145051_20250507_230551.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145052_20250507_231020.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145053_20250507_231241.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145054_20250507_231325.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145055_20250507_231414.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145056_20250507_231500.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145057_20250507_231600.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145058_20250507_231645.zip\n",
      "  Already extracted: S4_Extract_xiangyan_145059_20250507_231716.zip\n",
      "\n",
      "Extraction complete! Extracted 0 new files.\n"
     ]
    }
   ],
   "source": [
    "# Extract all ZIP files (this may take a few minutes)\n",
    "print(\"Extracting ZIP files...\")\n",
    "extracted_count = 0\n",
    "\n",
    "for zip_file in zip_files:\n",
    "    zip_path = os.path.join(reports_folder, zip_file)\n",
    "    extract_folder = os.path.join(reports_folder, zip_file.replace('.zip', ''))\n",
    "    \n",
    "    # Check if already extracted\n",
    "    if not os.path.exists(extract_folder):\n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_folder)\n",
    "            extracted_count += 1\n",
    "            if extracted_count % 10 == 0:\n",
    "                print(f\"  Extracted {extracted_count}/{len(zip_files)} files...\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error extracting {zip_file}: {e}\")\n",
    "    else:\n",
    "        print(f\"  Already extracted: {zip_file}\")\n",
    "\n",
    "print(f\"\\nExtraction complete! Extracted {extracted_count} new files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6093b47",
   "metadata": {},
   "source": [
    "## Step 3: Build PDF Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be66ee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 extracted folders\n",
      "\n",
      "First few folders:\n",
      "  - S4_Extract_xiangyan_145031_20250507_221605\n",
      "  - S4_Extract_xiangyan_145032_20250507_221817\n",
      "  - S4_Extract_xiangyan_145033_20250507_222016\n"
     ]
    }
   ],
   "source": [
    "# Find all extracted folders\n",
    "extracted_folders = [f for f in os.listdir(reports_folder) \n",
    "                     if os.path.isdir(os.path.join(reports_folder, f))]\n",
    "\n",
    "print(f\"Found {len(extracted_folders)} extracted folders\")\n",
    "print(f\"\\nFirst few folders:\")\n",
    "for folder in extracted_folders[:3]:\n",
    "    print(f\"  - {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcde10f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built mapping for 2787 PDFs\n",
      "\n",
      "Sample report numbers from PDFs:\n",
      "  - 81421443: S4_Extract_xiangyan_145031_20250507_221605\n",
      "  - 81428801: S4_Extract_xiangyan_145031_20250507_221605\n",
      "  - 81443557: S4_Extract_xiangyan_145031_20250507_221605\n",
      "  - 81465854: S4_Extract_xiangyan_145032_20250507_221817\n",
      "  - 81527069: S4_Extract_xiangyan_145031_20250507_221605\n"
     ]
    }
   ],
   "source": [
    "# Build mapping: report_number -> PDF path and ZIP folder location\n",
    "report_pdf_map = {}\n",
    "report_zip_map = {}  # Track which ZIP folder each report came from\n",
    "\n",
    "for folder in extracted_folders:\n",
    "    folder_path = os.path.join(reports_folder, folder)\n",
    "    police_reports_path = os.path.join(folder_path, \"Police Crash Reports\")\n",
    "    \n",
    "    # Check if Police Crash Reports subfolder exists\n",
    "    if os.path.exists(police_reports_path):\n",
    "        pdf_files = [f for f in os.listdir(police_reports_path) if f.endswith('.pdf')]\n",
    "        \n",
    "        for pdf_file in pdf_files:\n",
    "            # Extract report number from filename: CrashReport_85828586.pdf\n",
    "            match = re.search(r'CrashReport_(\\d+)\\.pdf', pdf_file)\n",
    "            if match:\n",
    "                report_num = match.group(1)\n",
    "                pdf_path = os.path.join(police_reports_path, pdf_file)\n",
    "                report_pdf_map[report_num] = pdf_path\n",
    "                report_zip_map[report_num] = folder  # Store the ZIP folder location\n",
    "\n",
    "print(f\"Built mapping for {len(report_pdf_map)} PDFs\")\n",
    "print(f\"\\nSample report numbers from PDFs:\")\n",
    "sample_keys = list(report_pdf_map.keys())[:5]\n",
    "for key in sample_keys:\n",
    "    print(f\"  - {key}: {report_zip_map[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05e9c65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample report numbers from Excel:\n",
      "  - 82089001\n",
      "  - 81994356\n",
      "  - 82877472\n",
      "  - 83350430\n",
      "  - 83353372\n",
      "  - 83353605\n",
      "  - 83360086\n",
      "  - 80823780\n",
      "  - 83968397\n",
      "  - 83671693\n"
     ]
    }
   ],
   "source": [
    "# Check sample of report numbers from Excel to ensure format matches\n",
    "print(\"Sample report numbers from Excel:\")\n",
    "sample_excel = df_filtered['HSMV_Report_Number'].head(10).astype(str).tolist()\n",
    "for num in sample_excel:\n",
    "    print(f\"  - {num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1738103b",
   "metadata": {},
   "source": [
    "## Step 4: Match Report Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9af9e7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Results:\n",
      "Match\n",
      "No     96\n",
      "Yes    15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Match rate: 13.51%\n"
     ]
    }
   ],
   "source": [
    "# Function to check if report number has matching PDF\n",
    "def check_match(report_number):\n",
    "    # Convert to string and clean\n",
    "    report_str = str(report_number).strip()\n",
    "    \n",
    "    # Remove any decimal points (in case of float conversion)\n",
    "    if '.' in report_str:\n",
    "        report_str = report_str.split('.')[0]\n",
    "    \n",
    "    return 'Yes' if report_str in report_pdf_map else 'No'\n",
    "\n",
    "# Apply matching\n",
    "df_filtered['Match'] = df_filtered['HSMV_Report_Number'].apply(check_match)\n",
    "\n",
    "print(\"Match Results:\")\n",
    "print(df_filtered['Match'].value_counts())\n",
    "print(f\"\\nMatch rate: {(df_filtered['Match'] == 'Yes').sum() / len(df_filtered) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc2b950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample MATCHED records:\n",
      "      HSMV_Report_Number Bike Type Match\n",
      "3756            85203537   Pedicab   Yes\n",
      "4727            85442822   Pedicab   Yes\n",
      "5318            87436908   Pedicab   Yes\n",
      "\n",
      "Sample UNMATCHED records:\n",
      "     HSMV_Report_Number          Bike Type Match\n",
      "403            82089001  Motorized bicycle    No\n",
      "530            81994356  Motorized bicycle    No\n",
      "745            82877472            E-trike    No\n"
     ]
    }
   ],
   "source": [
    "# Show samples of matched and unmatched records\n",
    "print(\"\\nSample MATCHED records:\")\n",
    "matched = df_filtered[df_filtered['Match'] == 'Yes'].head(3)\n",
    "print(matched[['HSMV_Report_Number', 'Bike Type', 'Match']])\n",
    "\n",
    "print(\"\\nSample UNMATCHED records:\")\n",
    "unmatched = df_filtered[df_filtered['Match'] == 'No'].head(3)\n",
    "print(unmatched[['HSMV_Report_Number', 'Bike Type', 'Match']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8d7fed",
   "metadata": {},
   "source": [
    "## Step 5: Extract Narratives from PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31966b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF extraction function defined!\n"
     ]
    }
   ],
   "source": [
    "def extract_narrative_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract the NARRATIVE section from a Florida Traffic Crash Report PDF\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        \n",
    "    Returns:\n",
    "        Extracted narrative text, or empty string if not found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            \n",
    "            # Extract text from all pages\n",
    "            full_text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                full_text += page.extract_text()\n",
    "            \n",
    "            # Look for NARRATIVE section\n",
    "            narrative_pattern = r'NARRATIVE\\s*[-\\s]*\\n(.*?)(?=REPORTING OFFICER|$)'\n",
    "            match = re.search(narrative_pattern, full_text, re.DOTALL | re.IGNORECASE)\n",
    "            \n",
    "            if match:\n",
    "                narrative_text = match.group(1).strip()\n",
    "                \n",
    "                # Clean up the narrative text\n",
    "                lines = narrative_text.split('\\n')\n",
    "                cleaned_lines = []\n",
    "                \n",
    "                for line in lines:\n",
    "                    # Skip header lines and dash lines\n",
    "                    if any(x in line for x in ['ID Number', 'Rank', 'Officer Agency', 'TROOPER', 'OFFICER']):\n",
    "                        if not any(word in line.upper() for word in ['REPORTING', 'OFFICER AGENCY PHONE']):\n",
    "                            continue\n",
    "                    if line.strip().replace('-', '').strip() == '':\n",
    "                        continue\n",
    "                    \n",
    "                    cleaned_lines.append(line.strip())\n",
    "                \n",
    "                # Join lines and clean up extra whitespace\n",
    "                narrative = ' '.join(cleaned_lines)\n",
    "                narrative = re.sub(r'\\s+', ' ', narrative).strip()\n",
    "                \n",
    "                return narrative\n",
    "            else:\n",
    "                return \"\"\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting from {pdf_path}: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "print(\"PDF extraction function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfac5eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing extraction with:\n",
      "  Report Number: 81421443\n",
      "  PDF Path: reports\\S4_Extract_xiangyan_145031_20250507_221605\\Police Crash Reports\\CrashReport_81421443.pdf\n",
      "\n",
      "Extracted Narrative:\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test extraction with one PDF\n",
    "sample_report_num = list(report_pdf_map.keys())[0]\n",
    "sample_pdf_path = report_pdf_map[sample_report_num]\n",
    "\n",
    "print(f\"Testing extraction with:\")\n",
    "print(f\"  Report Number: {sample_report_num}\")\n",
    "print(f\"  PDF Path: {sample_pdf_path}\\n\")\n",
    "\n",
    "test_narrative = extract_narrative_from_pdf(sample_pdf_path)\n",
    "print(\"Extracted Narrative:\")\n",
    "print(\"=\" * 80)\n",
    "print(test_narrative[:500] + \"...\" if len(test_narrative) > 500 else test_narrative)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "374986b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting narratives from PDFs...\n",
      "This may take several minutes...\n",
      "\n",
      "\n",
      "Narratives extracted: 14 out of 111 records\n",
      "Extraction rate: 12.61%\n"
     ]
    }
   ],
   "source": [
    "# Extract narratives for all matched reports\n",
    "def get_narrative_for_report(row):\n",
    "    \"\"\"Get narrative for a report if it has a matching PDF\"\"\"\n",
    "    if row['Match'] == 'No':\n",
    "        return ''\n",
    "    \n",
    "    report_str = str(row['HSMV_Report_Number']).strip()\n",
    "    if '.' in report_str:\n",
    "        report_str = report_str.split('.')[0]\n",
    "    \n",
    "    if report_str in report_pdf_map:\n",
    "        pdf_path = report_pdf_map[report_str]\n",
    "        return extract_narrative_from_pdf(pdf_path)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "print(\"Extracting narratives from PDFs...\")\n",
    "print(\"This may take several minutes...\\n\")\n",
    "\n",
    "# Apply extraction\n",
    "df_filtered['Narrative'] = df_filtered.apply(get_narrative_for_report, axis=1)\n",
    "\n",
    "# Count results\n",
    "narratives_extracted = (df_filtered['Narrative'] != '').sum()\n",
    "print(f\"\\nNarratives extracted: {narratives_extracted} out of {len(df_filtered)} records\")\n",
    "print(f\"Extraction rate: {(narratives_extracted / len(df_filtered) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fe26521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample records with extracted narratives:\n",
      "\n",
      "Report Number: 85203537\n",
      "Bike Type: Pedicab\n",
      "Match: Yes\n",
      "Narrative: ID Number Rank Name Troop / Post Officer Agency Phone Number Date Created V01 and NM01 was traveling east in the left lane on Universal Blvd east of Convention Way. NM02 and NM03 were passengers on th...\n",
      "--------------------------------------------------------------------------------\n",
      "Report Number: 87436908\n",
      "Bike Type: Pedicab\n",
      "Match: Yes\n",
      "Narrative: Vehicle 1 was stopped in traffic on Universal Blvd facing southbound at the intersection of Major Blvd in the right lane. The Cyclist (person 2) was directly to the right (West) of Vehicle 1 facing th...\n",
      "--------------------------------------------------------------------------------\n",
      "Report Number: 87441667\n",
      "Bike Type: Motorized bicycle\n",
      "Match: Yes\n",
      "Narrative: Vehicle 1 was traveling East on E. Colonial Dr and approaching the intersection with Fashion Square Mall Entrance. Vehicle 1 was in the left turn lane. The cyclist was operating a gas powered bicycle ...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Show sample of extracted narratives\n",
    "print(\"Sample records with extracted narratives:\\n\")\n",
    "sample_with_narrative = df_filtered[df_filtered['Narrative'] != ''].head(3)\n",
    "\n",
    "for idx, row in sample_with_narrative.iterrows():\n",
    "    print(f\"Report Number: {row['HSMV_Report_Number']}\")\n",
    "    print(f\"Bike Type: {row['Bike Type']}\")\n",
    "    print(f\"Match: {row['Match']}\")\n",
    "    print(f\"Narrative: {row['Narrative'][:200]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d02795c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding ZIP folder location column...\n",
      "\n",
      "ZIP folder locations tracked: 15 out of 111 records\n",
      "\n",
      "Sample records with ZIP folder location:\n",
      "      HSMV_Report_Number          Bike Type Match  \\\n",
      "3756            85203537            Pedicab   Yes   \n",
      "4727            85442822            Pedicab   Yes   \n",
      "5318            87436908            Pedicab   Yes   \n",
      "5480            87441667  Motorized bicycle   Yes   \n",
      "5531            87443630  Motorized bicycle   Yes   \n",
      "\n",
      "                             ZIP_Folder_Location  \n",
      "3756  S4_Extract_xiangyan_145031_20250507_221605  \n",
      "4727  S4_Extract_xiangyan_145032_20250507_221817  \n",
      "5318  S4_Extract_xiangyan_145034_20250507_222144  \n",
      "5480  S4_Extract_xiangyan_145034_20250507_222144  \n",
      "5531  S4_Extract_xiangyan_145034_20250507_222144  \n"
     ]
    }
   ],
   "source": [
    "# Add ZIP folder location for tracking missing narratives\n",
    "def get_zip_folder_location(row):\n",
    "    \"\"\"Get the ZIP folder location for a report\"\"\"\n",
    "    if row['Match'] == 'No':\n",
    "        return ''\n",
    "    \n",
    "    report_str = str(row['HSMV_Report_Number']).strip()\n",
    "    if '.' in report_str:\n",
    "        report_str = report_str.split('.')[0]\n",
    "    \n",
    "    if report_str in report_zip_map:\n",
    "        return report_zip_map[report_str]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "print(\"Adding ZIP folder location column...\")\n",
    "df_filtered['ZIP_Folder_Location'] = df_filtered.apply(get_zip_folder_location, axis=1)\n",
    "\n",
    "# Show statistics\n",
    "zip_locations_filled = (df_filtered['ZIP_Folder_Location'] != '').sum()\n",
    "print(f\"\\nZIP folder locations tracked: {zip_locations_filled} out of {len(df_filtered)} records\")\n",
    "print(f\"\\nSample records with ZIP folder location:\")\n",
    "print(df_filtered[df_filtered['ZIP_Folder_Location'] != ''][['HSMV_Report_Number', 'Bike Type', 'Match', 'ZIP_Folder_Location']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d847a",
   "metadata": {},
   "source": [
    "## Step 6: Statistics and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86e92279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Total records: 111\n",
      "Unique HSMV Report Numbers: 111\n",
      "Unique Bike Types: 10\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "PDF MATCH STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Records with matching PDFs (Yes): 15\n",
      "Records without matching PDFs (No): 96\n",
      "Match rate: 13.51%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "NARRATIVE EXTRACTION STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Rows with Narrative filled: 14\n",
      "Rows with Narrative empty: 97\n",
      "Percentage filled: 12.61%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "BIKE TYPE DISTRIBUTION\n",
      "--------------------------------------------------------------------------------\n",
      "Bike Type\n",
      "E-bike                  42\n",
      "Motorized bicycle       37\n",
      "Pedicab                 16\n",
      "E-trike                  4\n",
      "Bicycle with trailer     3\n",
      "Police bike              2\n",
      "Adult tricycle           2\n",
      "Bike share               2\n",
      "Tandem                   2\n",
      "Recumbent trike          1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "MISSING VALUES SUMMARY\n",
      "--------------------------------------------------------------------------------\n",
      "HSMV_Report_Number     0\n",
      "Bike Type              0\n",
      "Narrative              0\n",
      "Match                  0\n",
      "ZIP_Folder_Location    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive statistics\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nTotal records: {len(df_filtered)}\")\n",
    "print(f\"Unique HSMV Report Numbers: {df_filtered['HSMV_Report_Number'].nunique()}\")\n",
    "print(f\"Unique Bike Types: {df_filtered['Bike Type'].nunique()}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"PDF MATCH STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "match_counts = df_filtered['Match'].value_counts()\n",
    "print(f\"Records with matching PDFs (Yes): {match_counts.get('Yes', 0)}\")\n",
    "print(f\"Records without matching PDFs (No): {match_counts.get('No', 0)}\")\n",
    "print(f\"Match rate: {(match_counts.get('Yes', 0) / len(df_filtered) * 100):.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"NARRATIVE EXTRACTION STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "narratives_filled = (df_filtered['Narrative'] != '').sum()\n",
    "narratives_empty = (df_filtered['Narrative'] == '').sum()\n",
    "print(f\"Rows with Narrative filled: {narratives_filled}\")\n",
    "print(f\"Rows with Narrative empty: {narratives_empty}\")\n",
    "print(f\"Percentage filled: {(narratives_filled / len(df_filtered) * 100):.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"BIKE TYPE DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "bike_type_counts = df_filtered['Bike Type'].value_counts()\n",
    "print(bike_type_counts)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"MISSING VALUES SUMMARY\")\n",
    "print(\"-\" * 80)\n",
    "print(df_filtered.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6494a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Data saved to: bike_data_with_narratives.xlsx\n",
      "================================================================================\n",
      "\n",
      "Columns in output file:\n",
      "  - HSMV_Report_Number\n",
      "  - Bike Type\n",
      "  - Narrative\n",
      "  - Match\n",
      "  - ZIP_Folder_Location\n",
      "\n",
      "Total rows: 111\n",
      "\n",
      "Note: ZIP_Folder_Location column added to track source folders for matched PDFs\n"
     ]
    }
   ],
   "source": [
    "# Save to Excel\n",
    "df_filtered.to_excel(output_file, index=False)\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"Data saved to: {output_file}\")\n",
    "print(f\"{'=' * 80}\")\n",
    "print(f\"\\nColumns in output file:\")\n",
    "for col in df_filtered.columns:\n",
    "    print(f\"  - {col}\")\n",
    "print(f\"\\nTotal rows: {len(df_filtered)}\")\n",
    "print(f\"\\nNote: ZIP_Folder_Location column added to track source folders for matched PDFs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2651d12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final DataFrame Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HSMV_Report_Number</th>\n",
       "      <th>Bike Type</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Match</th>\n",
       "      <th>ZIP_Folder_Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>82089001</td>\n",
       "      <td>Motorized bicycle</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>81994356</td>\n",
       "      <td>Motorized bicycle</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>82877472</td>\n",
       "      <td>E-trike</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>83350430</td>\n",
       "      <td>Pedicab</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>83353372</td>\n",
       "      <td>Motorized bicycle</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>83353605</td>\n",
       "      <td>Police bike</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>83360086</td>\n",
       "      <td>Bicycle with trailer</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>80823780</td>\n",
       "      <td>E-trike</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>83968397</td>\n",
       "      <td>Adult tricycle</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>83671693</td>\n",
       "      <td>Recumbent trike</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HSMV_Report_Number             Bike Type Narrative Match  \\\n",
       "403             82089001     Motorized bicycle              No   \n",
       "530             81994356     Motorized bicycle              No   \n",
       "745             82877472               E-trike              No   \n",
       "927             83350430               Pedicab              No   \n",
       "1031            83353372     Motorized bicycle              No   \n",
       "1205            83353605           Police bike              No   \n",
       "1487            83360086  Bicycle with trailer              No   \n",
       "1556            80823780               E-trike              No   \n",
       "2079            83968397        Adult tricycle              No   \n",
       "2100            83671693       Recumbent trike              No   \n",
       "\n",
       "     ZIP_Folder_Location  \n",
       "403                       \n",
       "530                       \n",
       "745                       \n",
       "927                       \n",
       "1031                      \n",
       "1205                      \n",
       "1487                      \n",
       "1556                      \n",
       "2079                      \n",
       "2100                      "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display final dataframe\n",
    "print(\"\\nFinal DataFrame Preview:\")\n",
    "df_filtered.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec75aba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bike_data_with_narratives.xlsx:\n",
      "Shape: (111, 5)\n",
      "Columns: ['HSMV_Report_Number', 'Bike Type', 'Narrative', 'Match', 'ZIP_Folder_Location']\n",
      "\n",
      "First few rows:\n",
      "   HSMV_Report_Number          Bike Type Narrative Match ZIP_Folder_Location\n",
      "0            82089001  Motorized bicycle       NaN    No                 NaN\n",
      "1            81994356  Motorized bicycle       NaN    No                 NaN\n",
      "2            82877472            E-trike       NaN    No                 NaN\n",
      "3            83350430            Pedicab       NaN    No                 NaN\n",
      "4            83353372  Motorized bicycle       NaN    No                 NaN\n",
      "\n",
      "================================================================================\n",
      "\n",
      "label.xlsx:\n",
      "Shape: (2787, 12)\n",
      "Columns: ['report_id', 'narrative', 'is_ebike_escooter', 'unsure', 'non-motorist type', 'notes', 'non_motorist_type', 'vehicle_body_type', 'non_motorist_location', 'non_motorist_action', 'posted_speed', 'estimated_speed']\n",
      "\n",
      "First few rows:\n",
      "    report_id                                          narrative  \\\n",
      "0  24012633.0  VEH 1 WAS AT N 40TH AV AND SHERIDAN ST. VEH 1 ...   \n",
      "1  24018175.0  THE VICTIM WAS RIDING HIS SCOOTER EASTBOUND IN...   \n",
      "2  24018185.0  V1 WAS TRAVELING SOUTHBOUND ON N FEDERAL HWY I...   \n",
      "3  24021620.0  On Tuesday July 21, 2020 at 1424 Hrs. I respon...   \n",
      "4  24027038.0  V1 was stopped at the intersection of Sheri Bl...   \n",
      "\n",
      "   is_ebike_escooter  unsure non-motorist type  \\\n",
      "0                0.0   False              bike   \n",
      "1                0.0    True           scooter   \n",
      "2                0.0    True           scooter   \n",
      "3                0.0   False    motorized bike   \n",
      "4                1.0   False            e-bike   \n",
      "\n",
      "                                               notes non_motorist_type  \\\n",
      "0  no mention of electric and bike had rear compa...       3 Bicyclist   \n",
      "1  scooter was in bicycle lane, no explicit menti...   4 Other Cyclist   \n",
      "2  PED 1 was on a scooter, still possible since c...   4 Other Cyclist   \n",
      "3                              high impact collision   4 Other Cyclist   \n",
      "4  pedeestrian on sidewalk with riding e-bike, cl...   4 Other Cyclist   \n",
      "\n",
      "  vehicle_body_type                non_motorist_location non_motorist_action  \\\n",
      "0   1 Passenger Car    1 Intersection - Marked Crosswalk  1 Crossing Roadway   \n",
      "1          3 Pickup                       6 Bicycle Lane             10 None   \n",
      "2   1 Passenger Car    1 Intersection - Marked Crosswalk  1 Crossing Roadway   \n",
      "3   1 Passenger Car    1 Intersection - Marked Crosswalk  1 Crossing Roadway   \n",
      "4          3 Pickup  2 Intersection - Unmarked Crosswalk  1 Crossing Roadway   \n",
      "\n",
      "   posted_speed  estimated_speed  \n",
      "0          30.0             20.0  \n",
      "1           NaN              NaN  \n",
      "2          35.0             15.0  \n",
      "3          15.0             10.0  \n",
      "4          25.0              2.0  \n"
     ]
    }
   ],
   "source": [
    "# Examine the structure of both files\n",
    "import pandas as pd\n",
    "\n",
    "# Load bike_data_with_narratives.xlsx\n",
    "bike_df = pd.read_excel('bike_data_with_narratives.xlsx')\n",
    "print(\"bike_data_with_narratives.xlsx:\")\n",
    "print(f\"Shape: {bike_df.shape}\")\n",
    "print(f\"Columns: {list(bike_df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(bike_df.head())\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Load label.xlsx\n",
    "label_df = pd.read_excel('label.xlsx')\n",
    "print(\"label.xlsx:\")\n",
    "print(f\"Shape: {label_df.shape}\")\n",
    "print(f\"Columns: {list(label_df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(label_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a143bb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nolabeluse.xlsx columns:\n",
      "['HSMV_Report_Number', 'Reporting_Agency', 'Form_Type', 'Year', 'Crash_Date', 'Crash_Time', 'City', 'County', 'Crash_Street', 'Intersecting_Street', 'Vehicles', 'Non_Motorists', 'Fatalities', 'Injuries', 'Alcohol_Related', 'Distraction_Related', 'Drug_Related', 'Weather_Condition', 'Light_Condition', 'Crash_Severity', 'Type_of_Intersection', 'Road_Sys_Identifier', 'Type_of_Shoulder', 'Road_Surf_Cond', 'Bicyclists', 'Possible_Injuries', 'Non_Incapacitating_Injuries', 'Incapacitating_Injuries', 'Fatalities_30_Days', 'Non_Traffic_Fatalities', 'S4_Mapping', 'S4_Decimal_Degree_Longitude', 'S4_Decimal_Degree_Latitude', 'S4_Albers_X', 'S4_Albers_Y', 'S4_Mapping_Date', 'Bike_Crash_Group_Number', 'Bike_Crash_Group', 'Bike_Crash_Type_Number', 'Bike_Crash_Type', 'Bike_Crash_Location', 'Bike_Bicyclist_Direction', 'Bike_Bicyclist_Position', 'Bike_Typing_Notes', 'Bike Type']\n",
      "\n",
      "Looking for location columns...\n",
      "Potential location columns: ['City', 'County', 'Bike_Crash_Location']\n",
      "\n",
      "Sample data from location columns:\n",
      "   HSMV_Report_Number Bike Type               City    County  \\\n",
      "0            81961357       NaN     Unincorporated    Orange   \n",
      "1            81960598       NaN            Orlando    Orange   \n",
      "2            81961052       NaN            Orlando    Orange   \n",
      "3            73989525       NaN  Altamonte Springs  Seminole   \n",
      "4            71671947       NaN          Kissimmee   Osceola   \n",
      "5            81899292       NaN            Orlando    Orange   \n",
      "6            81963764       NaN     Unincorporated    Orange   \n",
      "7            80814541       NaN              Ocoee    Orange   \n",
      "8            82065601       NaN   Lake Buena Vista    Orange   \n",
      "9            81986071       NaN            Orlando    Orange   \n",
      "\n",
      "         Bike_Crash_Location  \n",
      "0               Intersection  \n",
      "1  Non-Intersection Location  \n",
      "2               Intersection  \n",
      "3               Intersection  \n",
      "4  Non-Intersection Location  \n",
      "5  Non-Intersection Location  \n",
      "6               Intersection  \n",
      "7               Intersection  \n",
      "8  Non-Intersection Location  \n",
      "9  Non-Intersection Location  \n"
     ]
    }
   ],
   "source": [
    "# Check if original file has location/zip information\n",
    "original_df = pd.read_excel('nolabeluse.xlsx')\n",
    "print(\"nolabeluse.xlsx columns:\")\n",
    "print(list(original_df.columns))\n",
    "print(f\"\\nLooking for location columns...\")\n",
    "location_cols = [col for col in original_df.columns if any(word in col.lower() for word in ['zip', 'location', 'city', 'county', 'address'])]\n",
    "print(f\"Potential location columns: {location_cols}\")\n",
    "\n",
    "# Show a sample if we found location columns\n",
    "if location_cols:\n",
    "    print(f\"\\nSample data from location columns:\")\n",
    "    print(original_df[['HSMV_Report_Number', 'Bike Type'] + location_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c4e1e5",
   "metadata": {},
   "source": [
    "## Task 1: Add Location (City & County) to bike_data_with_narratives.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "81bc5bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base bike data (no location columns):\n",
      "Shape: (111, 5)\n",
      "Columns: ['HSMV_Report_Number', 'Bike Type', 'Narrative', 'Match', 'ZIP_Folder_Location']\n",
      "\n",
      "First 10 rows:\n",
      "   HSMV_Report_Number             Bike Type Narrative Match  \\\n",
      "0            82089001     Motorized bicycle       NaN    No   \n",
      "1            81994356     Motorized bicycle       NaN    No   \n",
      "2            82877472               E-trike       NaN    No   \n",
      "3            83350430               Pedicab       NaN    No   \n",
      "4            83353372     Motorized bicycle       NaN    No   \n",
      "5            83353605           Police bike       NaN    No   \n",
      "6            83360086  Bicycle with trailer       NaN    No   \n",
      "7            80823780               E-trike       NaN    No   \n",
      "8            83968397        Adult tricycle       NaN    No   \n",
      "9            83671693       Recumbent trike       NaN    No   \n",
      "\n",
      "  ZIP_Folder_Location  \n",
      "0                      \n",
      "1                      \n",
      "2                      \n",
      "3                      \n",
      "4                      \n",
      "5                      \n",
      "6                      \n",
      "7                      \n",
      "8                      \n",
      "9                      \n"
     ]
    }
   ],
   "source": [
    "# Prepare base bike data (no location columns)\n",
    "bike_df_updated = pd.read_excel('bike_data_with_narratives.xlsx')\n",
    "\n",
    "# Drop location columns if present\n",
    "location_cols = [col for col in ['City', 'County'] if col in bike_df_updated.columns]\n",
    "if location_cols:\n",
    "    bike_df_updated = bike_df_updated.drop(columns=location_cols)\n",
    "\n",
    "# Ensure ZIP_Folder_Location exists\n",
    "if 'ZIP_Folder_Location' not in bike_df_updated.columns:\n",
    "    bike_df_updated['ZIP_Folder_Location'] = ''\n",
    "\n",
    "# Keep only the usual columns for final output\n",
    "base_cols = ['HSMV_Report_Number', 'Bike Type', 'Narrative', 'Match', 'ZIP_Folder_Location']\n",
    "bike_df_updated = bike_df_updated[base_cols]\n",
    "\n",
    "# If not a match, clear ZIP_Folder_Location\n",
    "bike_df_updated.loc[bike_df_updated['Match'] != 'Yes', 'ZIP_Folder_Location'] = ''\n",
    "\n",
    "print(\"Base bike data (no location columns):\")\n",
    "print(f\"Shape: {bike_df_updated.shape}\")\n",
    "print(f\"Columns: {list(bike_df_updated.columns)}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(bike_df_updated.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e92bb73",
   "metadata": {},
   "source": [
    "## Task 2: Combine label.xlsx with bike_data_with_narratives.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24eaf929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted label data:\n",
      "Shape: (2680, 5)\n",
      "Columns: ['HSMV_Report_Number', 'Bike Type', 'Narrative', 'Match', 'ZIP_Folder_Location']\n",
      "\n",
      "First 10 rows:\n",
      "   HSMV_Report_Number       Bike Type  \\\n",
      "0            24012633            bike   \n",
      "1            24018175         scooter   \n",
      "2            24018185         scooter   \n",
      "3            24021620  motorized bike   \n",
      "4            24027038          e-bike   \n",
      "5            24027069       e-scooter   \n",
      "6            24027114          e-bike   \n",
      "7            24027139          e-bike   \n",
      "8            24032662          e-bike   \n",
      "9            24033091            bike   \n",
      "\n",
      "                                           Narrative Match ZIP_Folder_Location  \n",
      "0  VEH 1 WAS AT N 40TH AV AND SHERIDAN ST. VEH 1 ...   n/a                      \n",
      "1  THE VICTIM WAS RIDING HIS SCOOTER EASTBOUND IN...   n/a                      \n",
      "2  V1 WAS TRAVELING SOUTHBOUND ON N FEDERAL HWY I...   n/a                      \n",
      "3  On Tuesday July 21, 2020 at 1424 Hrs. I respon...   n/a                      \n",
      "4  V1 was stopped at the intersection of Sheri Bl...   n/a                      \n",
      "5  NON MOTORIST 1 WAS TRAVELING NORTH BOUND IN TH...   n/a                      \n",
      "6  V1 WAS TURNING ONTO WALTON BLVD FROM NOVA RD. ...   n/a                      \n",
      "7  V1 was entering the roadway from the driveway ...   n/a                      \n",
      "8  V1 was traveling north on SR 5 (Ridgewood Aven...   n/a                      \n",
      "9  On 2/25/21, V1 driven by P1 in the parking lot...   n/a                      \n"
     ]
    }
   ],
   "source": [
    "# Prepare label.xlsx data to match the structure (no location columns)\n",
    "label_df_formatted = label_df[['report_id', 'non-motorist type', 'narrative']].copy()\n",
    "\n",
    "# Rename columns to match bike_data structure\n",
    "label_df_formatted.rename(columns={\n",
    "    'report_id': 'HSMV_Report_Number',\n",
    "    'non-motorist type': 'Bike Type',\n",
    "    'narrative': 'Narrative'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add Match and ZIP_Folder_Location columns\n",
    "label_df_formatted['Match'] = 'n/a'\n",
    "label_df_formatted['ZIP_Folder_Location'] = ''\n",
    "\n",
    "# Drop rows with NaN in HSMV_Report_Number before converting to int\n",
    "label_df_formatted = label_df_formatted.dropna(subset=['HSMV_Report_Number'])\n",
    "\n",
    "# Convert report_id to integer to match HSMV_Report_Number format\n",
    "label_df_formatted['HSMV_Report_Number'] = label_df_formatted['HSMV_Report_Number'].astype(int)\n",
    "\n",
    "# Reorder columns to match final structure\n",
    "label_df_formatted = label_df_formatted[['HSMV_Report_Number', 'Bike Type', 'Narrative', 'Match', 'ZIP_Folder_Location']]\n",
    "\n",
    "print(\"Formatted label data:\")\n",
    "print(f\"Shape: {label_df_formatted.shape}\")\n",
    "print(f\"Columns: {list(label_df_formatted.columns)}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(label_df_formatted.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "585e8607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data:\n",
      "Shape: (2791, 5)\n",
      "bike_data_with_narratives rows: 111\n",
      "label.xlsx rows: 2680\n",
      "Total combined rows: 2791\n",
      "\n",
      "Columns: ['HSMV_Report_Number', 'Bike Type', 'Narrative', 'Match', 'ZIP_Folder_Location']\n",
      "\n",
      "Sample from bike_data_with_narratives (first 5 rows):\n",
      "   HSMV_Report_Number          Bike Type Narrative Match ZIP_Folder_Location\n",
      "0            82089001  Motorized bicycle       NaN    No                    \n",
      "1            81994356  Motorized bicycle       NaN    No                    \n",
      "2            82877472            E-trike       NaN    No                    \n",
      "3            83350430            Pedicab       NaN    No                    \n",
      "4            83353372  Motorized bicycle       NaN    No                    \n",
      "\n",
      "Sample from label.xlsx (rows 111 to 116):\n",
      "     HSMV_Report_Number       Bike Type  \\\n",
      "111            24012633            bike   \n",
      "112            24018175         scooter   \n",
      "113            24018185         scooter   \n",
      "114            24021620  motorized bike   \n",
      "115            24027038          e-bike   \n",
      "\n",
      "                                             Narrative Match  \\\n",
      "111  VEH 1 WAS AT N 40TH AV AND SHERIDAN ST. VEH 1 ...   n/a   \n",
      "112  THE VICTIM WAS RIDING HIS SCOOTER EASTBOUND IN...   n/a   \n",
      "113  V1 WAS TRAVELING SOUTHBOUND ON N FEDERAL HWY I...   n/a   \n",
      "114  On Tuesday July 21, 2020 at 1424 Hrs. I respon...   n/a   \n",
      "115  V1 was stopped at the intersection of Sheri Bl...   n/a   \n",
      "\n",
      "    ZIP_Folder_Location  \n",
      "111                      \n",
      "112                      \n",
      "113                      \n",
      "114                      \n",
      "115                      \n"
     ]
    }
   ],
   "source": [
    "# Combine bike_data_with_narratives with formatted label data\n",
    "combined_df = pd.concat([bike_df_updated, label_df_formatted], ignore_index=True)\n",
    "\n",
    "print(\"Combined data:\")\n",
    "print(f\"Shape: {combined_df.shape}\")\n",
    "print(f\"bike_data_with_narratives rows: {len(bike_df_updated)}\")\n",
    "print(f\"label.xlsx rows: {len(label_df_formatted)}\")\n",
    "print(f\"Total combined rows: {len(combined_df)}\")\n",
    "print(f\"\\nColumns: {list(combined_df.columns)}\")\n",
    "print(f\"\\nSample from bike_data_with_narratives (first 5 rows):\")\n",
    "print(combined_df.head())\n",
    "print(f\"\\nSample from label.xlsx (rows {len(bike_df_updated)} to {len(bike_df_updated)+5}):\")\n",
    "print(combined_df.iloc[len(bike_df_updated):len(bike_df_updated)+5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9abf366",
   "metadata": {},
   "source": [
    "## Task 3: Classify Bike Types into 3 Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7599fc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All unique bike types and their counts:\n",
      "Bike Type\n",
      "e-scooter                              50\n",
      "E-bike                                 42\n",
      "Motorized bicycle                      37\n",
      "e-bike                                 18\n",
      "Pedicab                                16\n",
      "bike                                   15\n",
      "scooter                                14\n",
      "motorized bike                          9\n",
      "motorized scooter                       6\n",
      "kick scooter                            5\n",
      "E-trike                                 4\n",
      "none                                    4\n",
      "pedestrian                              3\n",
      "gas bike                                3\n",
      "skateboard                              3\n",
      "Bicycle with trailer                    3\n",
      "Tandem                                  2\n",
      "moped                                   2\n",
      "cyclist                                 2\n",
      "unknown                                 2\n",
      "Bike share                              2\n",
      "Police bike                             2\n",
      "pedecycle                               2\n",
      "Adult tricycle                          2\n",
      "eunicycle                               2\n",
      "bicycle, skateboard                     1\n",
      "bicycle, manual scooter                 1\n",
      "seated electric scooter                 1\n",
      "toy e-bike                              1\n",
      "atv                                     1\n",
      "motorized wheelchair                    1\n",
      "one-wheel eskateboard                   1\n",
      "Recumbent trike                         1\n",
      "motorized standing scooter              1\n",
      "dirt bike                               1\n",
      "e-skateboard                            1\n",
      "pedicab                                 1\n",
      "pedal scooters                          1\n",
      "e or gas scooter                        1\n",
      "toy bicycle                             1\n",
      "small recreational child motorcycle     1\n",
      "tadpole tricycle                        1\n",
      "minibike                                1\n",
      "tricycle                                1\n",
      "two person scooter                      1\n",
      "three wheel pedal scooter               1\n",
      "powered bike                            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total unique bike types: 47\n"
     ]
    }
   ],
   "source": [
    "# First, let's see all unique bike types in the combined data\n",
    "unique_bike_types = combined_df['Bike Type'].value_counts()\n",
    "print(\"All unique bike types and their counts:\")\n",
    "print(unique_bike_types)\n",
    "print(f\"\\nTotal unique bike types: {len(unique_bike_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7033c254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bike Type Classification:\n",
      "================================================================================\n",
      "\n",
      "Bike Type Group\n",
      "Other (Non-motorists or Cyclists)    2622\n",
      "E-bike                                103\n",
      "E-scooter                              66\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "\n",
      "E-bike:\n",
      "--------------------------------------------------------------------------------\n",
      "Total records: 103\n",
      "Unique bike types: 6\n",
      "\n",
      "Top bike types in this group:\n",
      "Bike Type\n",
      "E-bike               42\n",
      "Motorized bicycle    37\n",
      "e-bike               18\n",
      "E-trike               4\n",
      "toy e-bike            1\n",
      "powered bike          1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "E-scooter:\n",
      "--------------------------------------------------------------------------------\n",
      "Total records: 66\n",
      "Unique bike types: 8\n",
      "\n",
      "Top bike types in this group:\n",
      "Bike Type\n",
      "e-scooter                     50\n",
      "motorized scooter              6\n",
      "kick scooter                   5\n",
      "e or gas scooter               1\n",
      "e-skateboard                   1\n",
      "motorized standing scooter     1\n",
      "one-wheel eskateboard          1\n",
      "seated electric scooter        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Other (Non-motorists or Cyclists):\n",
      "--------------------------------------------------------------------------------\n",
      "Total records: 2622\n",
      "Unique bike types: 33\n",
      "\n",
      "Top bike types in this group:\n",
      "Bike Type\n",
      "Pedicab                 16\n",
      "bike                    15\n",
      "scooter                 14\n",
      "motorized bike           9\n",
      "none                     4\n",
      "skateboard               3\n",
      "gas bike                 3\n",
      "pedestrian               3\n",
      "Bicycle with trailer     3\n",
      "Tandem                   2\n",
      "eunicycle                2\n",
      "moped                    2\n",
      "cyclist                  2\n",
      "unknown                  2\n",
      "Police bike              2\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create classification function for 3 groups\n",
    "def classify_bike_type(bike_type):\n",
    "    \"\"\"\n",
    "    Classify bike types into 3 categories:\n",
    "    1. E-bike\n",
    "    2. E-scooter\n",
    "    3. Other (Non-motorists or Cyclists)\n",
    "    \"\"\"\n",
    "    if pd.isna(bike_type):\n",
    "        return 'Other (Non-motorists or Cyclists)'\n",
    "    \n",
    "    bike_type_lower = str(bike_type).lower()\n",
    "    \n",
    "    # E-bike: vehicles powered partly or entirely by electricity (motorized bikes and pedal-assisted bikes)\n",
    "    ebike_keywords = [\n",
    "        'e-bike', 'motorized bicycle', 'e-trike', 'electric bicycle', \n",
    "        'powered bike', 'toy e-bike', 'ebike'\n",
    "    ]\n",
    "    if any(keyword in bike_type_lower for keyword in ebike_keywords):\n",
    "        return 'E-bike'\n",
    "    \n",
    "    # E-scooter: electric scooters, standing or seated, powered by battery\n",
    "    escooter_keywords = [\n",
    "        'e-scooter', 'motorized scooter', 'motorized standing scooter',\n",
    "        'kick scooter', 'seated electric scooter', 'e or gas scooter',\n",
    "        'e-skateboard', 'one-wheel'\n",
    "    ]\n",
    "    if any(keyword in bike_type_lower for keyword in escooter_keywords):\n",
    "        return 'E-scooter'\n",
    "    \n",
    "    # Other: human-powered vehicles, cyclists, non-motorized bikes\n",
    "    # This includes: bike, pedicab, bicycle with trailer, pedestrian, skateboard, police bike,\n",
    "    # adult tricycle, bike share, tandem, eunicycle, pedecycle, cyclist, moped, recumbent trike,\n",
    "    # tadpole tricycle, three wheel pedal scooter, tricycle, minibike, dirt bike, \n",
    "    # motorized wheelchair, ATV, etc.\n",
    "    return 'Other (Non-motorists or Cyclists)'\n",
    "\n",
    "# Apply classification\n",
    "combined_df['Bike Type Group'] = combined_df['Bike Type'].apply(classify_bike_type)\n",
    "\n",
    "# Show statistics for each group\n",
    "print(\"Bike Type Classification:\")\n",
    "print(\"=\"*80)\n",
    "group_counts = combined_df['Bike Type Group'].value_counts()\n",
    "print(f\"\\n{group_counts}\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show sample bike types in each group\n",
    "for group in ['E-bike', 'E-scooter', 'Other (Non-motorists or Cyclists)']:\n",
    "    print(f\"\\n{group}:\")\n",
    "    print(\"-\" * 80)\n",
    "    group_data = combined_df[combined_df['Bike Type Group'] == group]\n",
    "    bike_types_in_group = group_data['Bike Type'].value_counts()\n",
    "    print(f\"Total records: {len(group_data)}\")\n",
    "    print(f\"Unique bike types: {len(bike_types_in_group)}\")\n",
    "    print(f\"\\nTop bike types in this group:\")\n",
    "    print(bike_types_in_group.head(15))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75d231d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL BIKE TYPE CLASSIFICATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total records: 2791\n",
      "\n",
      "Breakdown by group:\n",
      "  1. E-bike:                                   103 records (  3.7%)\n",
      "  2. E-scooter:                                 66 records (  2.4%)\n",
      "  3. Other (Non-motorists or Cyclists):      2622 records ( 93.9%)\n",
      "\n",
      "================================================================================\n",
      "Sample records from each group:\n",
      "================================================================================\n",
      "\n",
      "E-bike:\n",
      " HSMV_Report_Number         Bike Type Match ZIP_Folder_Location\n",
      "           82089001 Motorized bicycle    No                    \n",
      "           81994356 Motorized bicycle    No                    \n",
      "           82877472           E-trike    No                    \n",
      "           83353372 Motorized bicycle    No                    \n",
      "           80823780           E-trike    No                    \n",
      "\n",
      "E-scooter:\n",
      " HSMV_Report_Number         Bike Type Match ZIP_Folder_Location\n",
      "           24027069         e-scooter   n/a                    \n",
      "           24065491 motorized scooter   n/a                    \n",
      "           24066383         e-scooter   n/a                    \n",
      "           24072808         e-scooter   n/a                    \n",
      "           24079338         e-scooter   n/a                    \n",
      "\n",
      "Other (Non-motorists or Cyclists):\n",
      " HSMV_Report_Number            Bike Type Match ZIP_Folder_Location\n",
      "           83350430              Pedicab    No                    \n",
      "           83353605          Police bike    No                    \n",
      "           83360086 Bicycle with trailer    No                    \n",
      "           83968397       Adult tricycle    No                    \n",
      "           83671693      Recumbent trike    No                    \n",
      "\n",
      "================================================================================\n",
      "NOTE: The 'Bike Type Group' column has been added to the dataframe\n",
      "      but NOT saved to the Excel file yet (as requested).\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display a comprehensive summary of the classification\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL BIKE TYPE CLASSIFICATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal records: {len(combined_df)}\")\n",
    "print(f\"\\nBreakdown by group:\")\n",
    "print(f\"  1. E-bike:                                 {len(combined_df[combined_df['Bike Type Group'] == 'E-bike']):>5} records ({len(combined_df[combined_df['Bike Type Group'] == 'E-bike'])/len(combined_df)*100:>5.1f}%)\")\n",
    "print(f\"  2. E-scooter:                              {len(combined_df[combined_df['Bike Type Group'] == 'E-scooter']):>5} records ({len(combined_df[combined_df['Bike Type Group'] == 'E-scooter'])/len(combined_df)*100:>5.1f}%)\")\n",
    "print(f\"  3. Other (Non-motorists or Cyclists):     {len(combined_df[combined_df['Bike Type Group'] == 'Other (Non-motorists or Cyclists)']):>5} records ({len(combined_df[combined_df['Bike Type Group'] == 'Other (Non-motorists or Cyclists)'])/len(combined_df)*100:>5.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Sample records from each group:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for group in ['E-bike', 'E-scooter', 'Other (Non-motorists or Cyclists)']:\n",
    "    print(f\"\\n{group}:\")\n",
    "    sample = combined_df[combined_df['Bike Type Group'] == group][['HSMV_Report_Number', 'Bike Type', 'Match', 'ZIP_Folder_Location']].head(5)\n",
    "    print(sample.to_string(index=False))\n",
    "    \n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NOTE: The 'Bike Type Group' column has been added to the dataframe\")\n",
    "print(\"      but NOT saved to the Excel file yet (as requested).\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb39767",
   "metadata": {},
   "source": [
    "## Task 4: AI-Based Classification using Narratives\n",
    "\n",
    "Use LLM to classify bike types from narrative text into one of 3 categories:\n",
    "- E-bike\n",
    "- E-scooter\n",
    "- Other (Non-motorists or Cyclists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf5a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client configured for UFL's LiteLLM Proxy\n",
      "Model: llama-3.3-70b-instruct\n"
     ]
    }
   ],
   "source": [
    "# Set up OpenAI client for UFL's LiteLLM Proxy\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"sk-esFPwPZnoQ5rtPd5aNSE-A\",\n",
    "    base_url=\"https://api.ai.it.ufl.edu\"  # LiteLLM Proxy is OpenAI compatible\n",
    ")\n",
    "\n",
    "print(\"OpenAI client configured for UFL's LiteLLM Proxy\")\n",
    "print(\"Model: gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d578f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI classification function defined!\n"
     ]
    }
   ],
   "source": [
    "# Function to classify bike type from narrative using AI\n",
    "def classify_with_ai(narrative):\n",
    "    \"\"\"\n",
    "    Use LLM to classify the vehicle type from crash narrative\n",
    "    Returns one of: 'E-bike', 'E-scooter', or 'Other (Non-motorists or Cyclists)'\n",
    "    \"\"\"\n",
    "    if not narrative or pd.isna(narrative) or str(narrative).strip() == '':\n",
    "        return 'Unknown - No narrative'\n",
    "    \n",
    "    # Create classification prompt\n",
    "    prompt = f\"\"\"Read the following crash report narrative and classify the non-motorist vehicle involved into ONE of these three categories:\n",
    "\n",
    "1. E-bike: Vehicles powered partly or entirely by electricity, including:\n",
    "   - E-bikes (electric bicycles, pedal-assisted bikes)\n",
    "   - Motorized bicycles\n",
    "   - E-trikes (electric tricycles)\n",
    "   - Electric bicycles\n",
    "   - Powered bikes\n",
    "   - Toy e-bikes\n",
    "\n",
    "2. E-scooter: Electric scooters (standing or seated), typically powered by battery, including:\n",
    "   - E-scooters\n",
    "   - Motorized scooters\n",
    "   - Motorized standing scooters\n",
    "   - Kick scooters\n",
    "   - Seated electric scooters\n",
    "   - E-skateboards\n",
    "   - One-wheel skateboards\n",
    "\n",
    "3. Other (Non-motorists or Cyclists): Human-powered vehicles, cyclists, and non-motorized transportation, including:\n",
    "   - Regular bikes/bicycles\n",
    "   - Pedicabs\n",
    "   - Bicycles with trailers\n",
    "   - Pedestrians\n",
    "   - Skateboards (non-electric)\n",
    "   - Police bikes\n",
    "   - Adult tricycles\n",
    "   - Bike share bicycles\n",
    "   - Tandems\n",
    "   - Unicycles\n",
    "   - Recumbent trikes\n",
    "   - Traditional scooters (non-motorized)\n",
    "   - Mopeds\n",
    "   - Dirt bikes\n",
    "   - ATVs\n",
    "   - Wheelchairs\n",
    "\n",
    "Crash Narrative:\n",
    "{narrative}\n",
    "\n",
    "Based on the narrative above, what type of vehicle was involved? Respond with ONLY one of these three options:\n",
    "- E-bike\n",
    "- E-scooter\n",
    "- Other (Non-motorists or Cyclists)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.1,  # Low temperature for consistent classification\n",
    "            max_tokens=50\n",
    "        )\n",
    "        \n",
    "        # Extract the classification from response\n",
    "        classification = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Ensure valid response\n",
    "        valid_categories = ['E-bike', 'E-scooter', 'Other (Non-motorists or Cyclists)']\n",
    "        if classification in valid_categories:\n",
    "            return classification\n",
    "        else:\n",
    "            # Try to find the category in the response\n",
    "            for category in valid_categories:\n",
    "                if category.lower() in classification.lower():\n",
    "                    return category\n",
    "            # If not found, default to 'Other (Non-motorists or Cyclists)'\n",
    "            return 'Other (Non-motorists or Cyclists)'\n",
    "    except Exception as e:\n",
    "        return f'Error - {str(e)}'\n",
    "\n",
    "print(\"AI classification function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc33b665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying AI classification to all records with narratives...\n",
      "================================================================================\n",
      "Total narratives to classify: 2694\n",
      "Progress: 50/2694\n",
      "Progress: 100/2694\n",
      "Progress: 150/2694\n",
      "Progress: 200/2694\n",
      "Progress: 250/2694\n",
      "Progress: 300/2694\n",
      "Progress: 350/2694\n",
      "Progress: 400/2694\n",
      "Progress: 450/2694\n",
      "Progress: 500/2694\n",
      "Progress: 550/2694\n",
      "Progress: 600/2694\n",
      "Progress: 650/2694\n",
      "Progress: 700/2694\n",
      "Progress: 750/2694\n",
      "Progress: 800/2694\n",
      "Progress: 850/2694\n",
      "Progress: 900/2694\n",
      "Progress: 950/2694\n",
      "Progress: 1000/2694\n",
      "Progress: 1050/2694\n",
      "Progress: 1100/2694\n",
      "Progress: 1150/2694\n",
      "Progress: 1200/2694\n",
      "Progress: 1250/2694\n",
      "Progress: 1300/2694\n",
      "Progress: 1350/2694\n",
      "Progress: 1400/2694\n",
      "Progress: 1450/2694\n",
      "Progress: 1500/2694\n",
      "Progress: 1550/2694\n",
      "Progress: 1600/2694\n",
      "Progress: 1650/2694\n",
      "Progress: 1700/2694\n",
      "Progress: 1750/2694\n",
      "Progress: 1800/2694\n",
      "Progress: 1850/2694\n",
      "Progress: 1900/2694\n",
      "Progress: 1950/2694\n",
      "Progress: 2000/2694\n",
      "Progress: 2050/2694\n",
      "Progress: 2100/2694\n",
      "Progress: 2150/2694\n",
      "Progress: 2200/2694\n",
      "Progress: 2250/2694\n",
      "Progress: 2300/2694\n",
      "Progress: 2350/2694\n",
      "Progress: 2400/2694\n",
      "Progress: 2450/2694\n",
      "Progress: 2500/2694\n",
      "Progress: 2550/2694\n",
      "Progress: 2600/2694\n",
      "Progress: 2650/2694\n",
      "Progress: 2694/2694\n",
      "\n",
      "================================================================================\n",
      "AI Classification Complete!\n",
      "================================================================================\n",
      "\n",
      "Summary:\n",
      "Total records: 2791\n",
      "Records with 'Final Bike Type' filled: 2694\n",
      "\n",
      "First 10 AI classifications:\n",
      "    HSMV_Report_Number          Bike Type                    Bike Type Group  \\\n",
      "17            85203537            Pedicab  Other (Non-motorists or Cyclists)   \n",
      "39            87436908            Pedicab  Other (Non-motorists or Cyclists)   \n",
      "43            87441667  Motorized bicycle                             E-bike   \n",
      "45            87443630  Motorized bicycle                             E-bike   \n",
      "52            87469273            E-trike                             E-bike   \n",
      "53            88911477             Tandem  Other (Non-motorists or Cyclists)   \n",
      "56            88911622            Pedicab  Other (Non-motorists or Cyclists)   \n",
      "61            83855964  Motorized bicycle                             E-bike   \n",
      "62            88365131     Adult tricycle  Other (Non-motorists or Cyclists)   \n",
      "65            24421523            Pedicab  Other (Non-motorists or Cyclists)   \n",
      "\n",
      "                      Final Bike Type  \n",
      "17  Other (Non-motorists or Cyclists)  \n",
      "39  Other (Non-motorists or Cyclists)  \n",
      "43  Other (Non-motorists or Cyclists)  \n",
      "45                             E-bike  \n",
      "52                             E-bike  \n",
      "53  Other (Non-motorists or Cyclists)  \n",
      "56  Other (Non-motorists or Cyclists)  \n",
      "61  Other (Non-motorists or Cyclists)  \n",
      "62  Other (Non-motorists or Cyclists)  \n",
      "65  Other (Non-motorists or Cyclists)  \n",
      "\n",
      " Saved combined data to NEW.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Apply AI classification to all records with narratives\n",
    "print(\"Applying AI classification to all records with narratives...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize the column if missing\n",
    "if 'Final Bike Type' not in combined_df.columns:\n",
    "    combined_df['Final Bike Type'] = ''\n",
    "\n",
    "# Only classify rows with narratives\n",
    "records_with_narratives = combined_df[combined_df['Narrative'].notna() & (combined_df['Narrative'] != '')]\n",
    "target_indices = records_with_narratives.index\n",
    "total = len(target_indices)\n",
    "print(f\"Total narratives to classify: {total}\")\n",
    "\n",
    "# Test the first narrative and stop if error\n",
    "first_idx = target_indices[0] if total > 0 else None\n",
    "if first_idx is not None:\n",
    "    narrative = combined_df.loc[first_idx, 'Narrative']\n",
    "    ai_classification = classify_with_ai(narrative)\n",
    "    combined_df.loc[first_idx, 'Final Bike Type'] = ai_classification\n",
    "    if isinstance(ai_classification, str) and ai_classification.startswith('Error -'):\n",
    "        print(f\"Error detected in first narrative: {ai_classification}\")\n",
    "        print(\"Stopping further classification.\")\n",
    "    else:\n",
    "        # Proceed with the rest only if first is not error\n",
    "        for i, idx in enumerate(target_indices[1:], 2):\n",
    "            narrative = combined_df.loc[idx, 'Narrative']\n",
    "            ai_classification = classify_with_ai(narrative)\n",
    "            combined_df.loc[idx, 'Final Bike Type'] = ai_classification\n",
    "            if i % 50 == 0 or i == total:\n",
    "                print(f\"Progress: {i}/{total}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AI Classification Complete!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Total records: {len(combined_df)}\")\n",
    "print(f\"Records with 'Final Bike Type' filled: {(combined_df['Final Bike Type'] != '').sum()}\")\n",
    "print(f\"\\nFirst 10 AI classifications:\")\n",
    "print(combined_df.loc[target_indices[:10], ['HSMV_Report_Number', 'Bike Type', 'Bike Type Group', 'Final Bike Type']])\n",
    "\n",
    "# Save the combined file (single output) with AI results\n",
    "combined_df.to_excel('NEW.xlsx', index=False)\n",
    "print(\"\\n Saved combined data to NEW.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa174de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPLETE DATAFRAME STRUCTURE\n",
      "================================================================================\n",
      "\n",
      "Columns in combined_df:\n",
      "  1. HSMV_Report_Number\n",
      "  2. Bike Type\n",
      "  3. Narrative\n",
      "  4. Match\n",
      "  5. ZIP_Folder_Location\n",
      "  6. Bike Type Group\n",
      "  7. Final Bike Type\n",
      "\n",
      "Total rows: 2791\n",
      "\n",
      "Sample data (first 5 rows with all columns):\n",
      "   HSMV_Report_Number          Bike Type Narrative Match ZIP_Folder_Location  \\\n",
      "0            82089001  Motorized bicycle       NaN    No                       \n",
      "1            81994356  Motorized bicycle       NaN    No                       \n",
      "2            82877472            E-trike       NaN    No                       \n",
      "3            83350430            Pedicab       NaN    No                       \n",
      "4            83353372  Motorized bicycle       NaN    No                       \n",
      "\n",
      "                     Bike Type Group Final Bike Type  \n",
      "0                             E-bike                  \n",
      "1                             E-bike                  \n",
      "2                             E-bike                  \n",
      "3  Other (Non-motorists or Cyclists)                  \n",
      "4                             E-bike                  \n",
      "\n",
      "================================================================================\n",
      "Column Statistics:\n",
      "================================================================================\n",
      "HSMV_Report_Number: 2791/2791 filled (100.0%)\n",
      "Bike Type: 272/2791 filled (9.7%)\n",
      "Narrative: 2694/2791 filled (96.5%)\n",
      "Match: 2791/2791 filled (100.0%)\n",
      "ZIP_Folder_Location: 15/2791 filled (0.5%)\n",
      "Bike Type Group: 2791/2791 filled (100.0%)\n",
      "Final Bike Type: 2694/2791 filled (96.5%)\n"
     ]
    }
   ],
   "source": [
    "# Display final dataframe structure with all new columns\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPLETE DATAFRAME STRUCTURE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nColumns in combined_df:\")\n",
    "for i, col in enumerate(combined_df.columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "print(f\"\\nTotal rows: {len(combined_df)}\")\n",
    "print(f\"\\nSample data (first 5 rows with all columns):\")\n",
    "print(combined_df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Column Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "for col in combined_df.columns:\n",
    "    non_empty = (combined_df[col].notna() & (combined_df[col] != '')).sum()\n",
    "    print(f\"{col}: {non_empty}/{len(combined_df)} filled ({non_empty/len(combined_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b77425d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL CLEANED DATA STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Total rows after cleaning: 2694\n",
      "Rows removed (empty narratives): 97\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FINAL COLUMN DISTRIBUTION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total unique classes in FINAL: 11\n",
      "\n",
      "Breakdown by class:\n",
      "  Other (Non-motorists or Cyclists)         1,199 records ( 44.51%)\n",
      "  E-scooter                                   951 records ( 35.30%)\n",
      "  E-bike                                      536 records ( 19.90%)\n",
      "  Unclear - Since the narrative mentions that Person #2 was \"pedaling a scooter\", it implies that the scooter is human-powered, not electric. Additionally, the make \"GOTRAX\" is known for producing both electric and non-electric scooters,      1 records (  0.04%)\n",
      "  Unclear - Since the narrative mentions a \"scooter\" but does not specify that it is electric or motorized, and given the context of the crash and the fact that the person involved is referred to as a \"cyclist\", it is more likely that      1 records (  0.04%)\n",
      "  Unclear - Since the narrative mentions that the pedalcyclist was riding a \"scooter\" but does not specify that it was electric or motorized, and given the context that it was being ridden on a sidewalk, it is more likely to be a traditional      1 records (  0.04%)\n",
      "  Unclear - The narrative mentions that the victim, Derrick Knights, was a \"cyclist\" and that the officer did not see the \"Ebike\" or its damage. However, the context suggests that Derrick Knights was the one riding the Ebike. \n",
      "\n",
      "Given      1 records (  0.04%)\n",
      "  Unclear - Since the narrative does not specify that the scooter was electric or motorized, and it is being ridden by a pedestrian, it is more likely to be a traditional, non-motorized scooter. \n",
      "\n",
      "- Other (Non-motorists or Cyclists      1 records (  0.04%)\n",
      "  Unclear - According to the narrative, the non-motorist vehicle involved was a \"pedestrian scooter\". Since it is referred to as a \"scooter\" and there is no indication that it was motorized or electric, it would fall under the      1 records (  0.04%)\n",
      "  Unclear - Based on the narrative, the non-motorist vehicle involved was a scooter, but it is not explicitly stated to be electric. However, given the context and the options provided, the most likely classification would be \"Other (Non-motorists or      1 records (  0.04%)\n",
      "  Unclear - According to the narrative, the vehicle involved was a \"(MOTOR BIKE)SCOOTER\", but since it's described as a motor bike scooter and not explicitly electric, and considering the context of the other options, it's more likely to be      1 records (  0.04%)\n",
      "\n",
      "Total with classification: 2694\n",
      "Total without classification (empty): 0\n",
      "\n",
      "================================================================================\n",
      " Saved cleaned data to NEW.xlsx\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL CLEANING AND SUMMARY ---\n",
    "# 1. Create FINAL column:\n",
    "def get_final_value(row):\n",
    "    # If both Bike Type and Narrative are present, use Bike Type Group\n",
    "    if pd.notna(row['Bike Type']) and str(row['Bike Type']).strip() != '' and pd.notna(row['Narrative']) and str(row['Narrative']).strip() != '':\n",
    "        return row['Bike Type Group']\n",
    "    # Otherwise, use AI column if available\n",
    "    elif pd.notna(row['Final Bike Type']) and str(row['Final Bike Type']).strip() != '':\n",
    "        return row['Final Bike Type']\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "combined_df['FINAL'] = combined_df.apply(get_final_value, axis=1)\n",
    "\n",
    "# 2. Remove rows with empty narratives\n",
    "combined_df_cleaned = combined_df[combined_df['Narrative'].notna() & (combined_df['Narrative'].str.strip() != '')].copy()\n",
    "\n",
    "# 3. Show comprehensive stats for cleaned data\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL CLEANED DATA STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal rows after cleaning: {len(combined_df_cleaned)}\")\n",
    "print(f\"Rows removed (empty narratives): {len(combined_df) - len(combined_df_cleaned)}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"FINAL COLUMN DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "final_counts = combined_df_cleaned['FINAL'].value_counts()\n",
    "print(f\"\\nTotal unique classes in FINAL: {combined_df_cleaned['FINAL'].nunique()}\")\n",
    "print(\"\\nBreakdown by class:\")\n",
    "for class_name in final_counts.index:\n",
    "    count = final_counts[class_name]\n",
    "    percentage = (count / len(combined_df_cleaned)) * 100\n",
    "    print(f\"  {class_name:40s} {count:>6,} records ({percentage:>6.2f}%)\")\n",
    "\n",
    "print(f\"\\nTotal with classification: {final_counts.sum()}\")\n",
    "print(f\"Total without classification (empty): {len(combined_df_cleaned) - final_counts.sum()}\")\n",
    "\n",
    "# 4. Save cleaned data to NEW.xlsx\n",
    "combined_df_cleaned.to_excel('NEW.xlsx', index=False)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" Saved cleaned data to NEW.xlsx\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e392f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "UPDATED FINAL CLEANED DATA STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Total rows after cleaning: 2694\n",
      "Rows removed (empty narratives): 97\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FINAL COLUMN DISTRIBUTION (UPDATED RULES)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total unique classes in FINAL: 11\n",
      "\n",
      "Breakdown by class:\n",
      "  Other (Non-motorists or Cyclists)         1,217 records ( 45.17%)\n",
      "  E-scooter                                   938 records ( 34.82%)\n",
      "  E-bike                                      531 records ( 19.71%)\n",
      "  Unclear - Since the narrative mentions that Person #2 was \"pedaling a scooter\", it implies that the scooter is human-powered, not electric. Additionally, the make \"GOTRAX\" is known for producing both electric and non-electric scooters,      1 records (  0.04%)\n",
      "  Unclear - Since the narrative mentions a \"scooter\" but does not specify that it is electric or motorized, and given the context of the crash and the fact that the person involved is referred to as a \"cyclist\", it is more likely that      1 records (  0.04%)\n",
      "  Unclear - Since the narrative mentions that the pedalcyclist was riding a \"scooter\" but does not specify that it was electric or motorized, and given the context that it was being ridden on a sidewalk, it is more likely to be a traditional      1 records (  0.04%)\n",
      "  Unclear - The narrative mentions that the victim, Derrick Knights, was a \"cyclist\" and that the officer did not see the \"Ebike\" or its damage. However, the context suggests that Derrick Knights was the one riding the Ebike. \n",
      "\n",
      "Given      1 records (  0.04%)\n",
      "  Unclear - Since the narrative does not specify that the scooter was electric or motorized, and it is being ridden by a pedestrian, it is more likely to be a traditional, non-motorized scooter. \n",
      "\n",
      "- Other (Non-motorists or Cyclists      1 records (  0.04%)\n",
      "  Unclear - According to the narrative, the non-motorist vehicle involved was a \"pedestrian scooter\". Since it is referred to as a \"scooter\" and there is no indication that it was motorized or electric, it would fall under the      1 records (  0.04%)\n",
      "  Unclear - Based on the narrative, the non-motorist vehicle involved was a scooter, but it is not explicitly stated to be electric. However, given the context and the options provided, the most likely classification would be \"Other (Non-motorists or      1 records (  0.04%)\n",
      "  Unclear - According to the narrative, the vehicle involved was a \"(MOTOR BIKE)SCOOTER\", but since it's described as a motor bike scooter and not explicitly electric, and considering the context of the other options, it's more likely to be      1 records (  0.04%)\n",
      "\n",
      "Total with classification: 2694\n",
      "Total without classification (empty): 0\n",
      "\n",
      "================================================================================\n",
      " Saved updated cleaned data to NEW.xlsx\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# --- UPDATE CLASSIFICATION: EXCLUDE MOTOR-POWERED FROM E-BIKE/E-SCOOTER ---\n",
    "# New rule: if \"motor\" appears in Bike Type, treat as Other (not E-bike/E-scooter)\n",
    "\n",
    "def classify_bike_type_updated(bike_type):\n",
    "    if pd.isna(bike_type):\n",
    "        return 'Other (Non-motorists or Cyclists)'\n",
    "\n",
    "    bike_type_str = str(bike_type).strip().lower()\n",
    "\n",
    "    # If it explicitly mentions motor, classify as Other\n",
    "    if 'motor' in bike_type_str:\n",
    "        return 'Other (Non-motorists or Cyclists)'\n",
    "\n",
    "    # E-bike: ONLY electric (no motor wording)\n",
    "    ebike_keywords = [\n",
    "        'e-bike', 'e bike', 'ebike', 'electric bicycle', 'electric bike',\n",
    "        'pedal assist', 'pedal-assisted', 'electric trike', 'e-trike'\n",
    "    ]\n",
    "    if any(keyword in bike_type_str for keyword in ebike_keywords):\n",
    "        return 'E-bike'\n",
    "\n",
    "    # E-scooter: ONLY electric (no motor wording)\n",
    "    escooter_keywords = [\n",
    "        'e-scooter', 'e scooter', 'electric scooter', 'e-skateboard',\n",
    "        'one-wheel', 'one wheel'\n",
    "    ]\n",
    "    if any(keyword in bike_type_str for keyword in escooter_keywords):\n",
    "        return 'E-scooter'\n",
    "\n",
    "    return 'Other (Non-motorists or Cyclists)'\n",
    "\n",
    "# Update Bike Type Group using the new rules\n",
    "combined_df['Bike Type Group'] = combined_df['Bike Type'].apply(classify_bike_type_updated)\n",
    "\n",
    "# Rebuild FINAL column with updated Bike Type Group\n",
    "combined_df['FINAL'] = combined_df.apply(get_final_value, axis=1)\n",
    "\n",
    "# Recreate cleaned dataset (remove empty narratives)\n",
    "combined_df_cleaned = combined_df[combined_df['Narrative'].notna() & (combined_df['Narrative'].str.strip() != '')].copy()\n",
    "\n",
    "# Updated stats\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"UPDATED FINAL CLEANED DATA STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal rows after cleaning: {len(combined_df_cleaned)}\")\n",
    "print(f\"Rows removed (empty narratives): {len(combined_df) - len(combined_df_cleaned)}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"FINAL COLUMN DISTRIBUTION (UPDATED RULES)\")\n",
    "print(\"-\" * 80)\n",
    "final_counts = combined_df_cleaned['FINAL'].value_counts()\n",
    "print(f\"\\nTotal unique classes in FINAL: {combined_df_cleaned['FINAL'].nunique()}\")\n",
    "print(\"\\nBreakdown by class:\")\n",
    "for class_name in final_counts.index:\n",
    "    count = final_counts[class_name]\n",
    "    percentage = (count / len(combined_df_cleaned)) * 100\n",
    "    print(f\"  {class_name:40s} {count:>6,} records ({percentage:>6.2f}%)\")\n",
    "\n",
    "print(f\"\\nTotal with classification: {final_counts.sum()}\")\n",
    "print(f\"Total without classification (empty): {len(combined_df_cleaned) - final_counts.sum()}\")\n",
    "\n",
    "# Save updated cleaned data\n",
    "combined_df_cleaned.to_excel('NEW.xlsx', index=False)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" Saved updated cleaned data to NEW.xlsx\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
